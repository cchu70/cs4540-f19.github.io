{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\LaTeX \\text{ commands here}\n",
    "\\newcommand{\\R}{\\mathbb{R}}\n",
    "\\newcommand{\\im}{\\text{im}\\,}\n",
    "\\newcommand{\\norm}[1]{||#1||}\n",
    "\\newcommand{\\inner}[1]{\\langle #1 \\rangle}\n",
    "\\newcommand{\\span}{\\mathrm{span}}\n",
    "\\newcommand{\\proj}{\\mathrm{proj}}\n",
    "\\newcommand{\\OPT}{\\mathrm{OPT}}\n",
    "\\newcommand{\\vx}{\\vec{x}}\n",
    "\\newcommand{\\I}{\\mathbb{I}}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "<hr style=\"border: 5px solid black\">\n",
    "\n",
    "**Georgia Tech, CS 4540**\n",
    "\n",
    "# Lecture 19: Logistic Regression\n",
    "\n",
    "Naveen Kodali and Jacob Abernethy\n",
    "*Date:  Tuesday, November 6, 2018*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Naive Bayes:  Problem\n",
    "\n",
    "- We will use **Naive Bayes** to solve the following classification problem:\n",
    "    - **Categorical** feature vector $\\vx = (x_1, x_2, \\dots, x_D)$ with length $D$\n",
    "        - Each feature $x_d \\in \\{0,1\\}$, $\\forall d = 1, \\dots, D$\n",
    "        - Note: you can allow for non-binary features - $x_d \\in \\{0,1, \\ldots M\\}$\n",
    "    - Predict discrete class label $y \\in \\{1, 2, \\dots, C \\}$\n",
    "\n",
    "- For example, in **Spam Mail Classification**,\n",
    "    - Predict whether an email is `SPAM` ($y=1$) or `HAM` ($y=0$)\n",
    "    - Use words / metadata in the email as features\n",
    "    - For simplicity, we can use **bag-of-words** features,\n",
    "        - Assume fixed vocabulary $V$ of size $|V| = D$\n",
    "        - Feature $x_d$, for $d \\in \\{1, 2, \\dots, D \\}$, indicates the existence of $d\\text{th}$ word in the email\n",
    "        - Eg. $x_d = 1$ if $d\\text{th}$ word is in the email; $x_d = 0$ otherwise\n",
    "        - In this case $M=2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Naive Bayes:  Independence Assumption and Full model\n",
    "\n",
    "- The essence of Naive Bayes is the **conditionally independence assumption**\n",
    "    $$\n",
    "    P(\\vx | y = c) = \\prod_{d=1}^D P(x_d | y=c)\n",
    "    $$\n",
    "    i.e., given the label, all features are independent.\n",
    "    \n",
    "- The **full generative** model of Naive Bayes is:\n",
    "    $$\n",
    "    \\begin{align}\n",
    "    P(y = c ) & = \\pi_c \\quad \\forall\\, c=0,1 \\\\\n",
    "    P(x_d = 1 | y = c ) &= \\theta_{cd} \\quad \\forall\\, d = 1,\\dots,D\n",
    "    \\end{align}\n",
    "    $$\n",
    "- Parameter $\\pi$ and $\\theta$ are learned from training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Naive Bayes: Prediction\n",
    "\n",
    "- Given the independence assumption and full model, for some new data $\\vx^{\\text{new}} = (x_1^{\\text{new}}, \\dots, x_D^{\\text{new}})$ we will classify based on\n",
    "    $$\n",
    "    \\begin{align}\n",
    "    y\n",
    "    &=\\underset{c \\in \\{0,1\\}}{\\arg \\max} P(y=c|\\vx = \\vx^{\\text{new}}) \\\\\n",
    "    &=\\underset{c \\in \\{0,1\\}}{\\arg \\max} P(\\vx = \\vx^{\\text{new}} | y=c) P(y=c) \\\\\n",
    "    &=\\underset{c \\in \\{0,1\\}}{\\arg \\max} P(y=c) \\prod \\nolimits_{d=1}^{D} P(x_d = x_d^{\\text{new}} | y=c) \\\\\n",
    "    &=\\boxed{\\underset{c \\in \\{0,1\\}}{\\arg \\max} \\pi_c \\prod \\nolimits_{d=1}^{D} \\theta_{cd}^{x_d^{\\text{new}}} (1-\\theta_{cd})^{1-x_d^{\\text{new}}}} \\\\\n",
    "    \\end{align}\n",
    "    $$\n",
    "    \n",
    "- So as long as we learned parameter $\\pi$ and $\\theta$, we could classify."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Naive Bayes:  Maximum Likelihood\n",
    "\n",
    "\n",
    "- We have alread solved the MLE for the multinomial distribution (categorical variable)! We observed that:\n",
    "    $$\n",
    "    \\hat{\\pi}_c = \\frac{N_c}{N} \\quad \\hat{\\theta}_{cd} = \\frac{N_{cd}}{N_c}\n",
    "    $$\n",
    "    where\n",
    "    - $N = $ Number of examples in $\\mathcal{D}$\n",
    "    - $N_c = $ Number of examples in class $c$ in $\\mathcal{D}$\n",
    "    - $N_{cd} = $ Number of examples in class $c$ with $x_d = 1$\n",
    "    \n",
    "- Intuitive Interpretation\n",
    "    - The class prior $\\pi$ is obtained from the density of each class $\\{1, \\dots, C\\}$ in $\\mathcal{D}$\n",
    "    - The class-conditional probability $\\theta_{cd}$ is obtained from the density of $x_d \\in \\{0,1\\}$ among all examples in class $c$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example dataset\n",
    "#### Example No.  |  Color  |  Type  |  Origin  |  Stolen?\n",
    "\n",
    "1 | Red | Sports | Domestic | Yes <br>\n",
    "2 | Red | Sports | Domestic | No <br>\n",
    "3 | Red | Sports | Domestic | Yes <br>\n",
    "4 | Yellow | Sports | Domestic | No <br>\n",
    "5 | Yellow | Sports | Imported | Yes <br>\n",
    "6 | Yellow | SUV | Imported | No <br>\n",
    "7 | Yellow | SUV | Imported | Yes <br>\n",
    "8 | Yellow | SUV | Domestic | No <br>\n",
    "9 | Red | SUV | Imported | No <br>\n",
    "10 | Red | Sports | Imported | Yes \n",
    "\n",
    "### Problem\n",
    "\n",
    "What is MLE of the parameters $\\theta$ and $\\mu$? \n",
    "\n",
    "For these parameters, what is P(Yes | Red Domestic SUV) and (No | Red Domestic SUV)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## MAP Estimation for Naive Bayes with Beta Prior\n",
    "\n",
    "In the above example, what if we never see a red car that is stolen (perhaps because we didn't have much data)? What will be $P(\\text{Stolen} | \\text{Red Imported Sports})$? The predicted probability will be 0! This is not desireable, since it would essentially be \"overfitting\" to the data.\n",
    "\n",
    "This is where we want a prior distribution. As we discussed previously, it's best to use a conjugate prior if you can, because the calculations are very convenient. The conjugate distribution to the binomial model is the *beta distribution*, parameterized by $\\alpha, \\beta > 0$:\n",
    "$$P(\\theta | \\alpha, \\beta) := \\frac{\\theta^{\\alpha - 1}(1-\\theta)^{\\beta - 1}}{B(\\alpha, \\beta)}$$\n",
    "where the normalization term $B$ is defined in terms of the [gamma function](https://en.wikipedia.org/wiki/Gamma_function), $B(\\alpha, \\beta) := \\frac{\\Gamma(\\alpha)\\Gamma(\\beta)}{\\Gamma(\\alpha + \\beta)}$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Naive Bayes:  Maximum a Posteriori\n",
    "\n",
    "\n",
    "- We have alread solved the MLE for Naive Bayes:\n",
    "    $$\n",
    "    \\hat{\\pi}_c = \\frac{N_c}{N} \\quad \\hat{\\theta}_{cd} = \\frac{N_{cd}}{N_c}\n",
    "    $$\n",
    "    where $N = $ #examples in the dataset, $N_c = $ #examples in class $c$ in dataset, $N_{cd} = $ #examples in class $c$ with $x_d = 1$\n",
    "    \n",
    "*Problem*: What is the MAP estimate of the parameters $\\theta_{cd}$ for this model, when we assume the prior on every $\\theta_{cd}$ is (independently) distributed according to $\\text{Beta}(\\alpha,\\beta)$?\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Answer\n",
    "\n",
    "You get the \"smoothed\" version of the counts:\n",
    "    $$\n",
    "     \\hat{\\theta}_{cd}^{\\text{MAP}(\\alpha,\\beta)} = \\frac{N_{cd} + \\alpha}{N_c + \\alpha + \\beta}\n",
    "    $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Binary is to Categorical as Beta is to Dirichlet\n",
    "\n",
    "We want to recall that the binomial model is a distribution on (counts of) *binary* variables. In the example above, all of the features $x_d$ took one of two values, and the class label YES/NO was also binary. In this case, you only need $\\theta_{cd}$ for each class $c \\in \\{0,1\\}$ and feature index $d = 1, \\ldots, D$\n",
    "\n",
    "*BUT* what if the features and classes can take one of more than two classes? In this case, we would assume our features and classes are *categorical* variables, and we would use the *multinomial* distribution to model them. If $X$ is a categorical variable with parameter vector $q$, then $P(X = j|q) = q_j$.\n",
    "\n",
    "The Beta prior is the \"good\" prior for the binomial distribution. For the categorical, it's the *Dirichlet* distribution. Let $q \\in \\Delta_K$ be some probability distribution on $K$ classes. Given parameters $\\alpha_1, \\ldots, \\alpha_K$, the Dirichlet distribution for $\\vec \\alpha$ has PDF:\n",
    "$$P_{\\vec \\alpha}(q) := \\frac{1}{B(\\vec \\alpha)} \\prod_{i=1}^K q_i^{\\alpha_i - 1}$$\n",
    "where $B(\\vec \\alpha) := \\frac{\\prod_{i=1}^K \\Gamma(\\alpha_i)}{\\Gamma(\\sum_{i=1}^K \\alpha_i)}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Classification Part 2: Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Our models so far:\n",
    "\n",
    "+ Linear regression\n",
    "    + Tries to find a model to predict $y$ from $x \\in \\R^d$, with parameters $\\theta \\in \\R^d$\n",
    "    + The variable $y$ is a *real* number\n",
    "    + Model assumes that $y$ is Gaussian with mean $x^\\top \\theta$ and variance $\\sigma^2$\n",
    "    + Model does **not** treat $x$ as a random variable\n",
    "+ Naive Bayes\n",
    "    + Tries to find a model to predict $y$ from $x$, with parameters $\\theta, \\mu$\n",
    "    + (Typically) the variable $y$ is a *categorical* variable\n",
    "    + (Typically) the coordinates of $x$ are *categorical* variables\n",
    "    + Model **does** treat $x$ as a random variable\n",
    "    + The model makes the (somewhat unusual) assumption that features $x = (x_1, \\ldots, x_D)$ are *independent once we condition on $y$*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## New Model: Logistic Regression\n",
    "\n",
    "+ Logistic regression\n",
    "    + Tries to find a model to predict $y$ from $x \\in \\R^d$, with parameters $\\theta \\in \\R^d$\n",
    "    + Model assumes that variable $y$ is a *categorical* variable with parameters $q$\n",
    "    + The prediction for $y$ is a probability distribution $q = P(y=1|x,\\theta), \\ldots, P(y=K|x,\\theta)$\n",
    "    + Model does **not** treat $x$ as a random variable\n",
    "    + Despite the name, LR is really a *classification* algorithm, not a regression alg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The likelihood model for Logistic Regression\n",
    "\n",
    "In this lecture, let us assume that the categorical label $y$ is *binary*, indeed $y \\in \\{-1,1\\}$, just to make things easier. But it is not hard to generalize this to multiclass (categorical > 2) settings.\n",
    "\n",
    "Given input $x$ and parameters $\\theta$, the prediction for $y$ can be viewed as a probability $q$ where\n",
    "$$q := P(y = 1 | x, \\theta) = \\frac{1}{1 + \\exp(-x^\\top \\theta)} = \\frac{\\exp(x^\\top \\theta)}{1 + \\exp(x^\\top \\theta)}.$$\n",
    "\n",
    "What's going on here? The problem is that $\\theta^\\top x$ is not guaranteed to be in $[0,1]$. We need to \"squash\" the real number $\\theta^\\top x$ into the probability space $[0,1]$. The standard way to do this is with the *sigmoid* function $\\sigma(s) = \\frac{1}{1 + \\exp(-s)}$.\n",
    "\n",
    "A nice property of the sigmoid: $\\sigma(-s) = (1-\\sigma(s))$. This is used a lot.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Log odds ratio\n",
    "\n",
    "It's often interesting to define what we call the *log-odds ratio* of a probability $p$ as $\\log \\frac{p}{1-p}$.\n",
    "\n",
    "\n",
    "With this in mind, we can also state this the Logistic Regression model as follows: the *log-odds ratio* is linear in $x$. That is, we have\n",
    "$$\\log \\frac{P(y = 1 | x, \\theta)}{P(y = -1 | x, \\theta)} = \\theta^\\top x$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## A Challenge for LR: No closed form MLE!\n",
    "\n",
    "The maximum likelihood estimator for the logistic regression is the following:\n",
    "$$\n",
    "\\begin{eqnarray*}\n",
    "\\theta^{\\text{MLE}} & := & \\arg\\max_{\\theta \\in \\R^d} \\sum_{i=1}^n \\log P(y_i | x_i, \\theta) \\\\\n",
    "& = & \\arg\\max_{\\theta \\in \\R^d} \\sum_{i=1}^n \\log \\left(\\sigma(x_i^\\top \\theta)^{\\mathbb{I}(y_i = 1)}(1-\\sigma(x_i^\\top \\theta))^{\\mathbb{I}(y_i = -1)}\\right) \\\\\n",
    "& = & \\arg\\max_{\\theta \\in \\R^d} \\sum_{i=1}^n \\log \\sigma(y_i(x_i^\\top \\theta))\n",
    "\\end{eqnarray*}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "If we define $h(x) = \\sigma(x^T\\theta)$, with some algebra, we can alternatively write down the loss for logistic regression as:\n",
    "$$L(\\theta) = \\sum_{i=1}^{m} (−y_i \\log(h(x_i)) − (1−y_i) \\log(1−h(x_i)))$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: \n",
    "\n",
    "Derive the gradient of the loss function above and what would the GD/SGD steps look like?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Full Gradient matrix form: $\\nabla_{\\theta} L(\\theta) = \\frac{1}{m} \\sum_{i=1}^{m} (h(x_i)−y_i) x_i$\n",
    "\n",
    "SGD Step co-ord wise: $\\theta_j = \\theta_j − \\alpha(h(x_i)−y_i)x_i^j$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: \n",
    "\n",
    "Derive the Hessian of the loss function above and what would the Newton's method step look like?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$H = \\frac{1}{m} \\sum_{i=1}^{m} \\left[ h(x_i)(1−h(x_i)) x_i x_i^T \\right]$\n",
    "    \n",
    "Newton Step: $\\theta = \\theta − H^{−1} \\nabla_\\theta L(\\theta)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does this work?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://raw.githubusercontent.com/cs4540-f18/cs4540-f18.github.io/master/lectures/logistic_x.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.linalg import inv\n",
    "\n",
    "#we read data from files line by line ------ dont worry about this part\n",
    "init = False\n",
    "file = open('logistic_x.txt', 'rb')\n",
    "for row in file:\n",
    "    r = row.decode('utf8').strip().split(' ')\n",
    "    if(init == False):\n",
    "        x_train = np.array([[1], [np.float(r[0])], [np.float(r[len(r)-1])]])\n",
    "        init = True\n",
    "    else:\n",
    "        x_train = np.append(x_train, [[1], [np.float(r[0])], [np.float(r[len(r)-1])]], axis=1);\n",
    "init = False\n",
    "file = open('logistic_y.txt', 'rb')\n",
    "for row in file:\n",
    "    if(init == False):\n",
    "        y_train = np.array([[np.float(row.strip())]])\n",
    "        init = True\n",
    "    else:\n",
    "        y_train = np.append(y_train, [[np.float(row.strip())]], axis=1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x11b441250>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#number of training examples ------- dont worry about this part\n",
    "m = y_train.shape[1]\n",
    "#init theta\n",
    "theta = np.array(np.zeros((x_train.shape[0], 1)))\n",
    "\n",
    "#sigmoid function\n",
    "def sigmoid(z):\n",
    "    return 1/(1+np.exp(-z))\n",
    "\n",
    "#we find all indices that make y=1 and y=0\n",
    "pos = np.flatnonzero(y_train == 1)\n",
    "neg = np.flatnonzero(y_train == 0)\n",
    "\n",
    "#plot data points\n",
    "plt.plot(x_train[1, pos], x_train[2, pos], 'ro')\n",
    "plt.plot(x_train[1, neg], x_train[2, neg], 'bo')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.66562014]\n",
      "[0.66518165]\n",
      "[0.66473473]\n",
      "[0.66428829]\n",
      "[0.66384282]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-17fdac0bf138>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;31m#calculate h, error, cost function for 1 training example\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0merror\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0myT\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mtmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0myT\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0myT\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-f83c588eaaea>\u001b[0m in \u001b[0;36msigmoid\u001b[0;34m(z)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#sigmoid function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m#we find all indices that make y=1 and y=0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "###This is training part which uses SGD/GD ----- dont run this in class but later compare it against Newton's \n",
    "###method which you will implement below.\n",
    "x = 0\n",
    "xT = x_train.T\n",
    "yT = y_train.T\n",
    "preJ = 0\n",
    "while True:\n",
    "    J = 0\n",
    "    x = x + 1;\n",
    "    for i in range(0, m):\n",
    "        #calculate h, error, cost function for 1 training example\n",
    "        h = sigmoid(theta.T.dot(x_train[:,i].T))\n",
    "        error = h.T - yT[i]\n",
    "        tmp = (-1)*yT[i]*np.log(h) - (1-yT[i])*np.log((1-h))\n",
    "        #accumulate cost function\n",
    "        J = J + tmp\n",
    "        nX = np.array([x_train[:,i]]).T\n",
    "        #update theta\n",
    "        theta = theta - 0.000003*(error*nX)\n",
    "    J=J/m\n",
    "    #just print cost function for every 1000steps\n",
    "    if(x == 1000):\n",
    "        x = 0\n",
    "        print(J)\n",
    "    if(preJ == 0):\n",
    "        preJ = J\n",
    "    #condition to stop learning when cost function do not decrease anymore\n",
    "    if((preJ) < (J)):\n",
    "        break\n",
    "    else:\n",
    "        preJ = J\n",
    "#we got theta\n",
    "print(theta)\n",
    "\n",
    "#plot the line that separate data poits\n",
    "plot_x = [np.ndarray.min(x_train[1:]), np.ndarray.max(x_train[1:])]\n",
    "plot_y = np.subtract(np.multiply(-(theta[2][0]/theta[1][0]), plot_x), theta[0][0]/theta[1][0])\n",
    "plt.plot(plot_x, plot_y, 'b-')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x110b50210>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "###Setting up as before ---- dont worry about this part\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.linalg import inv\n",
    "\n",
    "init = False\n",
    "file = open('logistic_x.txt', 'rb')\n",
    "for row in file:\n",
    "    r = row.decode('utf8').strip().split(' ')\n",
    "    if(init == False):\n",
    "        x_train = np.array([[1], [np.float(r[0])], [np.float(r[len(r)-1])]])\n",
    "        init = True\n",
    "    else:\n",
    "        x_train = np.append(x_train, [[1], [np.float(r[0])], [np.float(r[len(r)-1])]], axis=1);\n",
    "init = False\n",
    "file = open('logistic_y.txt', 'rb')\n",
    "for row in file:\n",
    "    if(init == False):\n",
    "        y_train = np.array([[np.float(row.strip())]])\n",
    "        init = True\n",
    "    else:\n",
    "        y_train = np.append(y_train, [[np.float(row.strip())]], axis=1);\n",
    "\n",
    "m = y_train.shape[1]\n",
    "theta = np.zeros((x_train.shape[0], 1))\n",
    "\n",
    "\n",
    "def sigmoid(z):\n",
    " return 1/(1+np.exp(-z))\n",
    "\n",
    "pos = np.flatnonzero(y_train == 1)\n",
    "neg = np.flatnonzero(y_train == 0)\n",
    "\n",
    "plt.plot(x_train[1, pos], x_train[2, pos], 'ro')\n",
    "plt.plot(x_train[1, neg], x_train[2, neg], 'bo')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6931471805599453\n",
      "0.4409414251174163\n",
      "0.40889169253305696\n",
      "0.40551077605901753\n",
      "0.40544745391660425\n",
      "0.4054474249282527\n",
      "0.4054474249282463\n",
      "0.4054474249282463\n",
      "0.4054474249282462\n",
      "0.4054474249282462\n",
      "[[-16.37874341]\n",
      " [  0.14834077]\n",
      " [  0.15890845]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "###Training with Newton's method which you will implement!!!!\n",
    "yT = y_train.T\n",
    "xT = x_train.T\n",
    "#iterator 500 steps\n",
    "for x in range(0, 10):\n",
    "    h = sigmoid(theta.T.dot(x_train))\n",
    "    error = h - y_train\n",
    "    tmp = (-1)*y_train*np.log(h) - (1-y_train)*np.log((1-h))\n",
    "    J = np.sum(tmp)/m;\n",
    "    #calculate H\n",
    "    #Write your line of code here\n",
    "    \n",
    "    #calculate gradient\n",
    "    #Write your line of code here\n",
    "    \n",
    "    #Update theta\n",
    "    #Write your lines of code here\n",
    "    print(J)\n",
    "    \n",
    "print(theta)\n",
    "\n",
    "plot_x = [np.ndarray.min(x_train[1:]), np.ndarray.max(x_train[1:])]\n",
    "plot_y = np.subtract(np.multiply(-(theta[2][0]/theta[1][0]), plot_x), theta[0][0]/theta[1][0])\n",
    "plt.plot(plot_x, plot_y, 'b-')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Answers\n",
    "## H = (h*(1-h)*(x_train)).dot(x_train.T)/m\n",
    "\n",
    "## dJ = np.sum(error*x_train, axis=1)/m\n",
    "\n",
    "###gradient = H-1.dJ\n",
    "###grad = inv(H).dot(dJ)\n",
    "###update theta\n",
    "###theta = theta - (np.array([grad])).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are not impressed, go home and try gradient descent!"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
